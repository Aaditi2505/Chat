# -*- coding: utf-8 -*-
"""add2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17H7GeXLk5E9wbHMdY1tS4bPDVAQNMKMj
"""

pip install streamlit pandas scikit-learn

import streamlit as st
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer

# Set up the Streamlit page
st.set_page_config(page_title="Kamaraj College FAQ Chatbot", layout="centered")

# Load model and data (with caching)
@st.cache_resource
def load_model_and_data():
    # Load the dataset
    df = pd.read_csv("kamaraj_college_faq.csv")
    df.dropna(inplace=True)

    # Encode answers to numerical labels
    le = LabelEncoder()
    df["Answer_Label"] = le.fit_transform(df["Answer"])

    # Vectorize questions
    vectorizer = TfidfVectorizer()
    X = vectorizer.fit_transform(df["Question"])
    y = df["Answer_Label"]

    # Train a logistic regression model
    model = LogisticRegression()
    model.fit(X, y)

    return model, vectorizer, le

# Load model, vectorizer, and encoder
model, vectorizer, label_encoder = load_model_and_data()

# App title
st.title("üéì Kamaraj College FAQ Chatbot")
st.markdown("Ask me anything related to **Kamaraj College of Engineering and Technology**! ü§ñ")

# User input
user_question = st.text_input("üí¨ Type your question here:")

# Button to get answer
if st.button("üîç Get Answer"):
    if not user_question.strip():
        st.warning("‚ö†Ô∏è Please enter a valid question.")
    else:
        # Vectorize user input and predict answer
        user_vector = vectorizer.transform([user_question])
        predicted_label = model.predict(user_vector)[0]
        predicted_answer = label_encoder.inverse_transform([predicted_label])[0]

        # Display answer
        st.success(f"üü¢ **Answer:** {predicted_answer}")

pip install gradio pyttsx3 scikit-learn pandas

pip install gradio pyttsx3 pandas scikit-learn openai-whisper

import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer
import pyttsx3
import gradio as gr
import whisper

# Load CSV and train model
df = pd.read_csv("kamaraj_college_faq.csv")
df.dropna(inplace=True)

le = LabelEncoder()
df["Answer_Label"] = le.fit_transform(df["Answer"])

vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(df["Question"])
y = df["Answer_Label"]

model = LogisticRegression()
model.fit(X, y)

# Text-to-speech function
def speak_text(text):
    engine = pyttsx3.init()
    engine.setProperty('rate', 150)
    engine.say(text)
    engine.runAndWait()

# Load whisper model for transcription
whisper_model = whisper.load_model("base")

# Combined chatbot function
def chatbot(audio=None, text=None):
    # If user speaks, transcribe it
    if audio is not None:
        audio_path = audio  # This is a temp .wav file
        result = whisper_model.transcribe(audio_path)
        user_input = result["text"]
    elif text:
        user_input = text
    else:
        return "Please provide a question."

    # Predict the answer
    vec = vectorizer.transform([user_input])
    prediction = model.predict(vec)[0]
    answer = le.inverse_transform([prediction])[0]

    # Speak answer
    speak_text(answer)

    return f"üó£Ô∏è You asked: {user_input}\n\n‚úÖ Answer: {answer}"

# Gradio Interface
iface = gr.Interface(
    fn=chatbot,
    inputs=[
        gr.Audio(sources=["microphone"], type="filepath", label="üé§ Speak your question"),
        gr.Textbox(lines=2, placeholder="Or type your question here", label="üìù Text question")
    ],
    outputs="text",
    title="üéì Kamaraj College FAQ - Voice + Text Chatbot",
    description="Ask via microphone or text. It will answer and speak back.",
)

iface.launch()