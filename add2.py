# -*- coding: utf-8 -*-
"""add2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17H7GeXLk5E9wbHMdY1tS4bPDVAQNMKMj
"""

# --- Imports ---
import streamlit as st
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer
import pyttsx3
import gradio as gr
import whisper

# --- Load Model and Data ---
@st.cache_resource
def load_model_and_data():
    df = pd.read_csv("kamaraj_college_faq.csv")
    df.dropna(inplace=True)

    le = LabelEncoder()
    df["Answer_Label"] = le.fit_transform(df["Answer"])

    vectorizer = TfidfVectorizer()
    X = vectorizer.fit_transform(df["Question"])
    y = df["Answer_Label"]

    model = LogisticRegression()
    model.fit(X, y)

    return model, vectorizer, le

# Shared model for both apps
model, vectorizer, label_encoder = load_model_and_data()

# --- Streamlit Chatbot UI ---
def run_streamlit_ui():
    st.set_page_config(page_title="Kamaraj College FAQ Chatbot", layout="centered")
    st.title("üéì Kamaraj College FAQ Chatbot")
    st.markdown("Ask me anything related to **Kamaraj College of Engineering and Technology**! ü§ñ")

    user_question = st.text_input("üí¨ Type your question here:")

    if st.button("üîç Get Answer"):
        if not user_question.strip():
            st.warning("‚ö†Ô∏è Please enter a valid question.")
        else:
            vec = vectorizer.transform([user_question])
            pred = model.predict(vec)[0]
            ans = label_encoder.inverse_transform([pred])[0]
            st.success(f"üü¢ **Answer:** {ans}")

# --- Text-to-Speech ---
def speak_text(text):
    engine = pyttsx3.init()
    engine.setProperty('rate', 150)
    engine.say(text)
    engine.runAndWait()

# --- Gradio Chatbot ---
def run_gradio_ui():
    whisper_model = whisper.load_model("base")

    def chatbot(audio=None, text=None):
        if audio is not None:
            result = whisper_model.transcribe(audio)
            user_input = result["text"]
        elif text:
            user_input = text
        else:
            return "Please provide a question."

        vec = vectorizer.transform([user_input])
        pred = model.predict(vec)[0]
        answer = label_encoder.inverse_transform([pred])[0]

        speak_text(answer)
        return f"üó£Ô∏è You asked: {user_input}\n\n‚úÖ Answer: {answer}"

    iface = gr.Interface(
        fn=chatbot,
        inputs=[
            gr.Audio(sources=["microphone"], type="filepath", label="üé§ Speak your question"),
            gr.Textbox(lines=2, placeholder="Or type your question here", label="üìù Text question")
        ],
        outputs="text",
        title="üéì Kamaraj College FAQ - Voice + Text Chatbot",
        description="Ask via microphone or text. It will answer and speak back.",
    )
    iface.launch()

# --- Entry Point ---
if __name__ == "__main__":
    # Comment out one of the below depending on which UI you want to run
    # run_streamlit_ui()  # For Streamlit interface
    run_gradio_ui()       # For Gradio interface
