# -*- coding: utf-8 -*-
"""add2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17H7GeXLk5E9wbHMdY1tS4bPDVAQNMKMj
"""
 
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer
from gtts import gTTS
import os
import uuid
import gradio as gr
import whisper

# --- Configuration ---
# Define the path for saving temporary audio files
AUDIO_OUTPUT_DIR = "temp_audio"
os.makedirs(AUDIO_OUTPUT_DIR, exist_ok=True)

# --- Data Loading and Model Training ---
try:
    df = pd.read_csv("kamaraj_college_faq.csv")
    df.dropna(inplace=True)
except FileNotFoundError:
    print("Error: 'kamaraj_college_faq.csv' not found. Please ensure the FAQ data file is in the same directory.")
    exit() # Exit if the data file is missing

# Encode answers
label_encoder = LabelEncoder()
df["Answer_Label"] = label_encoder.fit_transform(df["Answer"])

# Vectorize questions
vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(df["Question"])
y = df["Answer_Label"]

# Train the model
model = LogisticRegression(max_iter=1000) # Increased max_iter for convergence
model.fit(X, y)

# --- Text-to-Speech Function ---
def save_tts_audio(text):
    """
    Generates an audio file from text using gTTS and returns its path.
    """
    tts = gTTS(text=text, lang='en')
    filename = os.path.join(AUDIO_OUTPUT_DIR, f"response_{uuid.uuid4().hex}.mp3")
    tts.save(filename)
    return filename

# --- Load Whisper Model ---
try:
    whisper_model = whisper.load_model("base")
except Exception as e:
    print(f"Error loading Whisper model: {e}")
    print("Please ensure you have the 'whisper' library installed and internet access for the first-time download.")
    exit()

# --- Chatbot Logic ---
def chatbot(audio=None, text=None):
    user_input = ""
    response_audio_path = None

    if audio:
        try:
            result = whisper_model.transcribe(audio)
            user_input = result["text"]
        except Exception as e:
            return "‚ùó An error occurred during audio transcription. Please try again or type your question.", None
    elif text:
        user_input = text
    else:
        return "‚ùó Please ask a question via text or voice.", None

    if not user_input.strip():
        return "‚ùó It seems you didn't provide a question. Please try again.", None

    # Predict answer
    vec = vectorizer.transform([user_input])
    prediction = model.predict(vec)[0]
    answer = label_encoder.inverse_transform([prediction])[0]

    # Generate and save audio for the answer
    response_audio_path = save_tts_audio(answer)

    # Return both text and audio
    return f"üó£Ô∏è You asked: {user_input}\n‚úÖ Answer: {answer}", response_audio_path

# --- Gradio Interface ---
iface = gr.Interface(
    fn=chatbot,
    inputs=[
        gr.Audio(sources=["microphone"], type="filepath", label="üé§ Speak your question"),
        gr.Textbox(lines=2, placeholder="Or type your question here", label="üìù Type your question")
    ],
    outputs=[
        gr.Textbox(label="Chatbot Response"),
        gr.Audio(label="Spoken Answer", type="filepath") # Use Gradio's Audio output for playback
    ],
    title="üéì Kamaraj College FAQ Chatbot",
    description="Ask about Kamaraj College by voice or text. The chatbot will respond and speak the answer.",
    allow_flagging="never" # Disable flagging
)

iface.launch()

# Optional: Clean up temporary audio files on exit (can be added if desired)
# import atexit
# def cleanup_audio_files():
#     import shutil
#     if os.path.exists(AUDIO_OUTPUT_DIR):
#         shutil.rmtree(AUDIO_OUTPUT_DIR)
# atexit.register(cleanup_audio_files)
